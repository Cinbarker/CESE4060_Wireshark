{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ouhHFEaaUu8V"
      },
      "outputs": [],
      "source": [
        "EXPORT_FIGURES = False # Whether to export svg figures (True) or plot them (False)\n",
        "DOWNLOAD_FIGURES = False # Whether to download the SVG figures as zip file"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2UyQ0lkGTJzx"
      },
      "source": [
        "# Loading Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Bq3doaFtE8c"
      },
      "outputs": [],
      "source": [
        "# Download data from git repo\n",
        "!wget -P data/ https://raw.githubusercontent.com/Cinbarker/CESE4060_Wireshark/main/processed_data/coffee_company.feather\n",
        "!wget -P data/ https://raw.githubusercontent.com/Cinbarker/CESE4060_Wireshark/main/processed_data/anne_and_max.feather\n",
        "!wget -P data/ https://raw.githubusercontent.com/Cinbarker/CESE4060_Wireshark/main/processed_data/ikea.feather\n",
        "!pip install -U kaleido"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yNteZxHFu36U"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "import statsmodels\n",
        "import statsmodels.api as sm\n",
        "\n",
        "# Load dataframes\n",
        "cc_df = pd.read_feather(\"data/coffee_company.feather\")\n",
        "am_df = pd.read_feather(\"data/anne_and_max.feather\")\n",
        "ik_df = pd.read_feather(\"data/ikea.feather\")\n",
        "\n",
        "# Convert timestamps\n",
        "cc_df[\"Sniff_Timestamp\"] = pd.to_datetime(cc_df[\"Sniff_Timestamp\"])\n",
        "am_df[\"Sniff_Timestamp\"] = pd.to_datetime(am_df[\"Sniff_Timestamp\"])\n",
        "ik_df[\"Sniff_Timestamp\"] = pd.to_datetime(ik_df[\"Sniff_Timestamp\"])\n",
        "\n",
        "# Remove outliers in from MacBook's Wi-Fi card\n",
        "am_df = am_df[(am_df[\"Antenna_Signal_1\"] != 0) & (am_df[\"Antenna_Noise\"] != 0)]\n",
        "cc_df = cc_df[(cc_df[\"Antenna_Signal_1\"] != 0) & (cc_df[\"Antenna_Noise\"] != 0)]\n",
        "ik_df = ik_df[(ik_df[\"Antenna_Signal_1\"] != 0) & (ik_df[\"Antenna_Noise\"] != 0)]\n",
        "\n",
        "# BSSIDs for each capture\n",
        "bssids_cc = [\"78:8a:20:d7:6c:53\"]\n",
        "bssids_am = ['d0:21:f9:bf:91:05', 'd2:21:f9:cf:91:05', 'd2:21:f9:af:91:05']\n",
        "bssids_ik = [\"f0:1d:2d:63:e2:2b\", \"f0:1d:2d:63:e2:29\", \"00:27:e3:7d:cb:81\", \"f0:1d:2d:64:03:4b\", \"f0:1d:2d:64:03:49\", \"f0:1d:2d:63:f7:c9\", \"f0:1d:2d:63:f7:cb\", \"00:27:e3:82:00:cb\", \"00:27:e3:81:cc:2b\", \"00:27:e3:82:00:c9\", \"00:27:e3:81:d1:a1\", \"00:27:e3:86:3e:0b\", \"f0:1d:2d:65:d2:6b\", \"f0:1d:2d:65:d2:69\", \"f0:1d:2d:65:e6:49\", \"f0:1d:2d:65:e6:4b\", \"00:27:e3:81:cc:21\", \"00:27:e3:7d:b7:81\", \"f0:1d:2d:63:c4:a9\", \"f0:1d:2d:66:f2:0b\", \"f0:1d:2d:66:f2:09\", \"f0:1d:2d:63:c4:ab\", \"f0:1d:2d:63:c4:ab\", \"00:27:e3:81:ce:61\", \"00:27:e3:90:62:a1\", \"00:27:e3:90:64:c9\", \"f0:1d:2d:65:d2:61\", \"00:27:e3:7d:c9:a1\", \"00:27:e3:7d:c9:ab\", \"00:27:e3:81:99:cb\", \"f0:1d:2d:65:dc:c1\", \"00:27:e3:81:99:c9\", \"f0:1d:2d:63:cb:a9\", \"00:27:e3:90:64:cb\", \"f0:1d:2d:63:cb:ab\", \"f0:1d:2d:65:ce:81\", \"00:27:e3:82:01:61\", \"f0:1d:2d:64:02:e1\", \"f0:1d:2d:66:dc:a1\", \"f0:1d:2d:63:f7:c1\", \"f0:1d:2d:63:e2:21\", \"00:27:e3:82:00:c1\", \"f0:1d:2d:65:e6:41\", \"f0:1d:2d:63:c4:a1\", \"00:27:e3:86:3e:01\", \"f0:1d:2d:64:03:41\", \"f0:1d:2d:63:cc:81\", \"00:27:e3:81:fd:6b\", \"00:27:e3:81:d5:a1\", \"f0:1d:2d:63:cb:a1\", \"f0:1d:2d:65:ea:a1\", \"00:27:e3:81:c3:a1\", \"00:27:e3:81:fd:61\", \"f0:1d:2d:63:f1:01\", \"f0:1d:2d:65:e9:81\", \"f0:1d:2d:66:f2:01\", \"f0:1d:2d:63:cd:e1\", \"00:27:e3:7d:cc:81\", \"f0:1d:2d:65:e0:c1\", \"00:27:e3:81:d1:ab\", \"f0:1d:2d:63:fe:e1\", \"00:27:e3:7d:cb:8b\", \"f0:1d:2d:63:ff:41\"]\n",
        "\n",
        "# Mapping to readable labels\n",
        "labels = {\n",
        "    \"Antenna_Signal_1\": \"Antenna Signal [dBm]\",\n",
        "    \"Antenna_Noise\": \"Antenna Noise [dBm]\",\n",
        "    \"Unique_Devices\": \"Number of Devices\",\n",
        "    \"Sniff_Timestamp\": \"Time\",\n",
        "    \"Interval\": \"Time Interval\",\n",
        "    \"DataRate\": \"Data Rate [Mb/s]\",\n",
        "    \"FC_Retry\": \"FC Retry\",\n",
        "    \"SNR\": \"SNR [dBm]\",\n",
        "    \"Avg_Noise\": \"Average Noise [dBm]\",\n",
        "    \"Avg_Quality\": \"Average Quality\",\n",
        "    \"Avg_SNR\": \"SNR\",\n",
        "    \"Number_Retries\": \"Number of Retries\",\n",
        "    \"Total_Packets\": \"Total Packets\",\n",
        "    \"Retry_Rate\": \"Retry Rate\"\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vuYEIBhE8gW3"
      },
      "outputs": [],
      "source": [
        "# Helper function to either show figures or save them as SVGs\n",
        "def save_or_show(fig, name: str):\n",
        "  if EXPORT_FIGURES:\n",
        "    !mkdir -p figures\n",
        "    fig.update_layout(\n",
        "      margin=dict(l=0,r=0,b=0,t=0),\n",
        "      paper_bgcolor='rgba(0,0,0,0)',\n",
        "      plot_bgcolor='rgba(0,0,0,0)'\n",
        "    )\n",
        "    fig.write_image(\"figures/\" + name + \".svg\")\n",
        "    print(\"Saved to figures/\" + name + \".svg\")\n",
        "  else:\n",
        "    fig.update_layout(title=name)\n",
        "    fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A2TN_WzwUQ2J"
      },
      "source": [
        "# Processing Data and Generating Figures of Results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JDOd6jAAs-ed"
      },
      "source": [
        "## Number of individual devices over time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qRWKmpIsBy1M"
      },
      "outputs": [],
      "source": [
        "# Plot unique data addresses as histogramm in 15 min intervals\n",
        "# 1. Exclude the AP's own BSSIDs from the unique devices\n",
        "# 2. Floor timestamps to 5-minute intervals\n",
        "# 3. Count the unique transmit addresses in each 5-minute interval\n",
        "# 4. Plot the number of unique transmit addresses in 5-minute intervals\n",
        "\n",
        "# For cc_df\n",
        "device_counts = (\n",
        "    cc_df.loc[~cc_df['Trans_Addr'].isin(bssids_cc)]\n",
        "    .assign(Interval=lambda df: df['Sniff_Timestamp'].dt.floor('5min'))\n",
        "    .groupby('Interval')['Trans_Addr'].nunique().reset_index(name='Unique_Devices')\n",
        ")\n",
        "fig = px.bar(device_counts, x=\"Interval\", y=\"Unique_Devices\", labels=labels)\n",
        "fig.update_layout(showlegend=False)\n",
        "save_or_show(fig, \"unique_devices_over_time_cc\")\n",
        "\n",
        "\n",
        "# For am_df\n",
        "device_counts = (\n",
        "    am_df.loc[~am_df['Trans_Addr'].isin(bssids_am)]\n",
        "    .assign(Interval=lambda df: df['Sniff_Timestamp'].dt.floor('5min'))\n",
        "    .groupby('Interval')['Trans_Addr'].nunique().reset_index(name='Unique_Devices')\n",
        ")\n",
        "fig = px.bar(device_counts, x=\"Interval\", y=\"Unique_Devices\", labels=labels)\n",
        "fig.update_layout(showlegend=False)\n",
        "save_or_show(fig, \"unique_devices_over_time_am\")\n",
        "\n",
        "# For ik_df\n",
        "device_counts = (\n",
        "    ik_df.loc[~ik_df['Trans_Addr'].isin(bssids_ik)]\n",
        "    .assign(Interval=lambda df: df['Sniff_Timestamp'].dt.floor('5min'))\n",
        "    .groupby('Interval')['Trans_Addr'].nunique().reset_index(name='Unique_Devices')\n",
        ")\n",
        "fig = px.bar(device_counts, x=\"Interval\", y=\"Unique_Devices\", labels=labels)\n",
        "fig.update_layout(showlegend=False)\n",
        "save_or_show(fig, \"unique_devices_over_time_ik\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NKYCumyx7Olb"
      },
      "source": [
        "## Antenna signal over time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IjufGufxxh0A"
      },
      "outputs": [],
      "source": [
        "fig = px.scatter(cc_df, x=\"Sniff_Timestamp\", y=\"Antenna_Signal_1\", labels=labels)\n",
        "save_or_show(fig, \"antenna_signal_vs_time_cc\")\n",
        "fig = px.scatter(am_df, x=\"Sniff_Timestamp\", y=\"Antenna_Signal_1\", labels=labels)\n",
        "save_or_show(fig, \"antenna_signal_vs_time_am\")\n",
        "fig = px.scatter(ik_df, x=\"Sniff_Timestamp\", y=\"Antenna_Signal_1\", labels=labels)\n",
        "save_or_show(fig, \"antenna_signal_vs_time_ik\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4UpSHgmU7NcF"
      },
      "source": [
        "## Antenna noise over time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7bI1oPgd_xw7"
      },
      "outputs": [],
      "source": [
        "fig = px.scatter(cc_df, x=\"Sniff_Timestamp\", y=\"Antenna_Noise\", labels=labels)\n",
        "save_or_show(fig, \"antenna_noise_vs_time_cc\")\n",
        "\n",
        "fig = px.scatter(am_df, x=\"Sniff_Timestamp\", y=\"Antenna_Noise\", labels=labels)\n",
        "save_or_show(fig, \"antenna_noise_vs_time_am\")\n",
        "\n",
        "fig = px.scatter(ik_df, x=\"Sniff_Timestamp\", y=\"Antenna_Noise\", labels=labels)\n",
        "save_or_show(fig, \"antenna_noise_vs_time_ik\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8pTExAVD7wct"
      },
      "source": [
        "## Antenna noise vs signal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WMwERlI3-CmB"
      },
      "outputs": [],
      "source": [
        "fig = px.scatter(cc_df, x=\"Antenna_Noise\", y=\"Antenna_Signal_1\", labels=labels)\n",
        "save_or_show(fig, \"antenna_noise_vs_signal_cc\")\n",
        "\n",
        "fig = px.scatter(am_df, x=\"Antenna_Noise\", y=\"Antenna_Signal_1\", labels=labels)\n",
        "save_or_show(fig, \"antenna_noise_vs_signal_am\")\n",
        "\n",
        "fig = px.scatter(ik_df, x=\"Antenna_Noise\", y=\"Antenna_Signal_1\", labels=labels)\n",
        "save_or_show(fig, \"antenna_noise_vs_signal_ik\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TnWTmLZ-AuVc"
      },
      "source": [
        "## Antenna Noise and Antenna Signal over Time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BKxZphv0Azih"
      },
      "outputs": [],
      "source": [
        "legend_layout = dict(\n",
        "    orientation=\"h\",\n",
        "    yanchor=\"bottom\",\n",
        "    y=1.02,    # slightly above the plot area\n",
        "    xanchor=\"right\",\n",
        "    x=1\n",
        ")\n",
        "\n",
        "fig = px.line(cc_df, x=\"Sniff_Timestamp\",\n",
        "              y=[\"Antenna_Signal_1\", \"Antenna_Noise\"],\n",
        "              labels=labels)\n",
        "fig.update_layout(\n",
        "    yaxis_title=\"Power [dBm]\",\n",
        "    legend=legend_layout\n",
        ")\n",
        "save_or_show(fig, \"antenna_signal&noise_vs_time_cc\")\n",
        "\n",
        "fig = px.line(am_df, x=\"Sniff_Timestamp\",\n",
        "              y=[\"Antenna_Signal_1\", \"Antenna_Noise\"],\n",
        "              labels=labels)\n",
        "fig.update_layout(\n",
        "    yaxis_title=\"Power [dBm]\",\n",
        "    legend=legend_layout\n",
        ")\n",
        "save_or_show(fig, \"antenna_signal&noise_vs_time_am\")\n",
        "\n",
        "fig = px.line(ik_df, x=\"Sniff_Timestamp\",\n",
        "              y=[\"Antenna_Signal_1\", \"Antenna_Noise\"],\n",
        "              labels=labels)\n",
        "fig.update_layout(\n",
        "    yaxis_title=\"Power [dBm]\",\n",
        "    legend=legend_layout\n",
        ")\n",
        "save_or_show(fig, \"antenna_signal&noise_vs_time_ik\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9tcp8KB-DYBo"
      },
      "source": [
        "## SNR over time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1FXFFpb3DZjH"
      },
      "outputs": [],
      "source": [
        "# print average snr value\n",
        "average_snr_cc = cc_df[\"SNR\"].mean()\n",
        "average_snr_am = am_df[\"SNR\"].mean()\n",
        "average_snr_ik = ik_df[\"SNR\"].mean()\n",
        "print(\"cc snr:\", average_snr_cc)\n",
        "print(\"am snr:\", average_snr_am)\n",
        "print(\"ik snr:\", average_snr_ik)\n",
        "\n",
        "#figure of SNR over time\n",
        "fig = px.line(cc_df, x=\"Sniff_Timestamp\", y=\"SNR\", labels=labels)\n",
        "save_or_show(fig, \"snr_over_time_cc\")\n",
        "fig = px.line(am_df, x=\"Sniff_Timestamp\", y=\"SNR\", labels=labels)\n",
        "save_or_show(fig, \"snr_over_time_am\")\n",
        "fig = px.line(ik_df, x=\"Sniff_Timestamp\", y=\"SNR\", labels=labels)\n",
        "save_or_show(fig, \"snr_over_time_ik\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wzzctbFpQzu2"
      },
      "source": [
        "## SNR over time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NOoGIw7Y9EL1"
      },
      "outputs": [],
      "source": [
        "fig = px.scatter(cc_df, x=\"Sniff_Timestamp\", y=\"SNR\", labels=labels)\n",
        "save_or_show(fig, \"snr_over_time_cc\")\n",
        "\n",
        "fig = px.scatter(am_df, x=\"Sniff_Timestamp\", y=\"SNR\", labels=labels)\n",
        "save_or_show(fig, \"snr_over_time_am\")\n",
        "\n",
        "fig = px.scatter(ik_df, x=\"Sniff_Timestamp\", y=\"SNR\", labels=labels)\n",
        "save_or_show(fig, \"snr_over_time_ik\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a3X9UUhVgS81"
      },
      "source": [
        "## SNR vs Retransmission Rate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BhxSe4DvgR-D"
      },
      "outputs": [],
      "source": [
        "# Ratio retransmissions devided be total number of transmissions\n",
        "# Scatter plot for SNR vs NumberOFRetransmissions/TotalNumberOfPackets\n",
        "# 1. Compute Retry Rate per SNR: Sum of FC_Retry / Total Transmissions at that SNR\n",
        "# 2. Compute actual Retry Rate\n",
        "\n",
        "# For cc\n",
        "retry_rate_per_snr = cc_df.groupby(\"SNR\").agg(\n",
        "    Retry_Rate=(\"FC_Retry\", \"sum\"),  # Sum of bad FC_Retry at that SNR\n",
        "    Total_Transmissions=(\"FC_Retry\", \"count\")  # Count of all transmissions at that SNR\n",
        ").reset_index()\n",
        "retry_rate_per_snr[\"Retry_Rate\"] = retry_rate_per_snr[\"Retry_Rate\"] / retry_rate_per_snr[\"Total_Transmissions\"]\n",
        "fig = px.scatter(retry_rate_per_snr, x=\"SNR\", y=\"Retry_Rate\", labels=labels, trendline=\"ols\")\n",
        "save_or_show(fig, \"snr_vs_retransmission_rate_cc\")\n",
        "\n",
        "\n",
        "# For am\n",
        "retry_rate_per_snr = am_df.groupby(\"SNR\").agg(\n",
        "    Retry_Rate=(\"FC_Retry\", \"sum\"),  # Sum of bad FC_Retry at that SNR\n",
        "    Total_Transmissions=(\"FC_Retry\", \"count\")  # Count of all transmissions at that SNR\n",
        ").reset_index()\n",
        "retry_rate_per_snr[\"Retry_Rate\"] = retry_rate_per_snr[\"Retry_Rate\"] / retry_rate_per_snr[\"Total_Transmissions\"]\n",
        "\n",
        "fig = px.scatter(retry_rate_per_snr, x=\"SNR\", y=\"Retry_Rate\", labels=labels, trendline=\"ols\")\n",
        "save_or_show(fig, \"snr_vs_retransmission_rate_am\")\n",
        "\n",
        "# For ik\n",
        "retry_rate_per_snr = ik_df.groupby(\"SNR\").agg(\n",
        "    Retry_Rate=(\"FC_Retry\", \"sum\"),  # Sum of bad FC_Retry at that SNR\n",
        "    Total_Transmissions=(\"FC_Retry\", \"count\")  # Count of all transmissions at that SNR\n",
        ").reset_index()\n",
        "retry_rate_per_snr[\"Retry_Rate\"] = retry_rate_per_snr[\"Retry_Rate\"] / retry_rate_per_snr[\"Total_Transmissions\"]\n",
        "\n",
        "fig = px.scatter(retry_rate_per_snr, x=\"SNR\", y=\"Retry_Rate\", labels=labels, trendline=\"ols\")\n",
        "save_or_show(fig, \"snr_vs_retransmission_rate_ik\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G4h6_A1qgX_e"
      },
      "source": [
        "## Retries vs SNR vs Transmissions in numbers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v79eBoBtahdv"
      },
      "outputs": [],
      "source": [
        "# 1. Exclude specific MAC addresses\n",
        "# 2. Create a new column for 5-minute intervals\n",
        "# 3. Count unique transmitter addresses per 5-minute interval\n",
        "# 4. Count retries per 5-minute interval\n",
        "# 5. Merge both counts on the 5-minute interval\n",
        "# 6. Scatter plot of retries vs. unique transmitters\n",
        "\n",
        "# For am\n",
        "am_df['5_min_interval'] = am_df['Sniff_Timestamp'].dt.floor('5min')\n",
        "am_filtered = am_df[~am_df['Trans_Addr'].isin(bssids_am)]\n",
        "am_filtered['5_min_interval'] = am_filtered['Sniff_Timestamp'].dt.floor('5min')\n",
        "device_counts_am = am_filtered.groupby('5_min_interval')['Trans_Addr'].nunique().reset_index(name='Unique_Devices')\n",
        "retries_am = am_df[\"FC_Retry\"].sum()\n",
        "dev_retries_am = am_df[\"FC_Retry\"].count()\n",
        "transmissions_am = am_df.groupby(\"5_min_interval\")[\"FC_Retry\"].count().reset_index(name=\"Count\")\n",
        "\n",
        "\n",
        "#Average percentage of retries over transmissions per minute\n",
        "print(\"am average percentage of retries over transmissions for AM:\", (retries_am/ dev_retries_am))\n",
        "#Max percentage of retries ocer transmissions per minute\n",
        "print(\"am max percentage of retries over transmissions for AM:\", (retries_am/ dev_retries_am).max())\n",
        "#Min percentage of retries ocer transmissions per minute\n",
        "print(\"am min percentage of retries over transmissions for AM:\", (retries_am/ dev_retries_am).min())\n",
        "#Average number of Devices per minuted\n",
        "print(\"am average number of devices per minute for AM:\", device_counts_am[\"Unique_Devices\"].mean())\n",
        "#Max number of Devices per minute\n",
        "print(\"am max number of devices per minute for AM:\", device_counts_am[\"Unique_Devices\"].max())\n",
        "#Min number of Devices per minute\n",
        "print(\"am min number of devices per minute for AM:\", device_counts_am[\"Unique_Devices\"].min())\n",
        "#Average number of Transmissions per minute\n",
        "print(\"am average number of transmissions per minute for AM:\", transmissions_am[\"Count\"].mean())\n",
        "#Max number of Transmissions per minute\n",
        "print(\"am max number of transmissions per minute for AM:\", transmissions_am[\"Count\"].max())\n",
        "#Min number of Transmissions per minute\n",
        "print(\"am min number of transmissions per minute for AM:\", transmissions_am[\"Count\"].min())\n",
        "#Average SNR\n",
        "print(\"am average SNR for AM:\", am_df[\"SNR\"].mean())\n",
        "#Max SNR\n",
        "print(\"am max SNR for AM:\", am_df[\"SNR\"].max())\n",
        "#Min SNR\n",
        "print(\"am min SNR for AM:\", am_df[\"SNR\"].min())\n",
        "#Average Data Rate\n",
        "print(\"am average Data Rate for AM:\", am_df[\"DataRate\"].mean())\n",
        "#Max Data Rate\n",
        "print(\"am max Data Rate for AM:\", am_df[\"DataRate\"].max())\n",
        "#Min Data Rate\n",
        "print(\"am min Data Rate for AM:\", am_df[\"DataRate\"].min())\n",
        "\n",
        "\n",
        "# For cc\n",
        "cc_df['5_min_interval'] = cc_df['Sniff_Timestamp'].dt.floor('5min')\n",
        "cc_filtered = cc_df[~cc_df['Trans_Addr'].isin(bssids_cc)]\n",
        "cc_filtered['5_min_interval'] = cc_filtered['Sniff_Timestamp'].dt.floor('5min')\n",
        "device_counts_cc = cc_filtered.groupby('5_min_interval')['Trans_Addr'].nunique().reset_index(name='Unique_Devices')\n",
        "retries_cc = cc_df[\"FC_Retry\"].sum()\n",
        "dev_retries_cc = cc_df[\"FC_Retry\"].count()\n",
        "transmissions_cc = cc_df.groupby(\"5_min_interval\")[\"FC_Retry\"].count().reset_index(name=\"Count\")\n",
        "\n",
        "# CC Statistics\n",
        "print(\"cc average percentage of retries over transmissions for CC:\", (retries_cc / dev_retries_cc).mean())\n",
        "print(\"cc max percentage of retries over transmissions for CC:\", (retries_cc / dev_retries_cc).max())\n",
        "print(\"cc min percentage of retries over transmissions for CC:\", (retries_cc / dev_retries_cc).min())\n",
        "print(\"cc average number of devices per minute for CC:\", device_counts_cc[\"Unique_Devices\"].mean())\n",
        "print(\"cc max number of devices per minute for CC:\", device_counts_cc[\"Unique_Devices\"].max())\n",
        "print(\"cc min number of devices per minute for CC:\", device_counts_cc[\"Unique_Devices\"].min())\n",
        "print(\"cc average number of transmissions per minute for CC:\", transmissions_cc[\"Count\"].mean())\n",
        "print(\"cc max number of transmissions per minute for CC:\", transmissions_cc[\"Count\"].max())\n",
        "print(\"cc min number of transmissions per minute for CC:\", transmissions_cc[\"Count\"].min())\n",
        "print(\"cc average SNR for CC:\", cc_df[\"SNR\"].mean())\n",
        "print(\"cc max SNR for CC:\", cc_df[\"SNR\"].max())\n",
        "print(\"cc min SNR for CC:\", cc_df[\"SNR\"].min())\n",
        "print(\"cc average Data Rate for CC:\", cc_df[\"DataRate\"].mean())\n",
        "print(\"cc max Data Rate for CC:\", cc_df[\"DataRate\"].max())\n",
        "print(\"cc min Data Rate for CC:\", cc_df[\"DataRate\"].min())\n",
        "\n",
        "# For ik\n",
        "ik_df['5_min_interval'] = ik_df['Sniff_Timestamp'].dt.floor('5min')\n",
        "ik_filtered = ik_df[~ik_df['Trans_Addr'].isin(bssids_ik)]\n",
        "ik_filtered['5_min_interval'] = ik_filtered['Sniff_Timestamp'].dt.floor('5min')\n",
        "device_counts_ik = ik_filtered.groupby('5_min_interval')['Trans_Addr'].nunique().reset_index(name='Unique_Devices')\n",
        "retries_ik = ik_df[\"FC_Retry\"].sum()\n",
        "dev_retries_ik = ik_df[\"FC_Retry\"].count()\n",
        "transmissions_ik = ik_df.groupby(\"5_min_interval\")[\"FC_Retry\"].count().reset_index(name=\"Count\")\n",
        "\n",
        "\n",
        "# IK Statistics\n",
        "print(\"ik average percentage of retries over transmissions for IK:\", (retries_ik / dev_retries_ik).mean())\n",
        "print(\"ik max percentage of retries over transmissions for IK:\", (retries_ik / dev_retries_ik).max())\n",
        "print(\"ik min percentage of retries over transmissions for IK:\", (retries_ik / dev_retries_ik).min())\n",
        "print(\"ik average number of devices per minute for IK:\", device_counts_ik[\"Unique_Devices\"].mean())\n",
        "print(\"ik max number of devices per minute for IK:\", device_counts_ik[\"Unique_Devices\"].max())\n",
        "print(\"ik min number of devices per minute for IK:\", device_counts_ik[\"Unique_Devices\"].min())\n",
        "print(\"ik average number of transmissions per minute for IK:\", transmissions_ik[\"Count\"].mean())\n",
        "print(\"ik max number of transmissions per minute for IK:\", transmissions_ik[\"Count\"].max())\n",
        "print(\"ik min number of transmissions per minute for IK:\", transmissions_ik[\"Count\"].min())\n",
        "print(\"ik average SNR for IK:\", ik_df[\"SNR\"].mean())\n",
        "print(\"ik max SNR for IK:\", ik_df[\"SNR\"].max())\n",
        "print(\"ik min SNR for IK:\", ik_df[\"SNR\"].min())\n",
        "print(\"ik average Data Rate for IK:\", ik_df[\"DataRate\"].mean())\n",
        "print(\"ik max Data Rate for IK:\", ik_df[\"DataRate\"].max())\n",
        "print(\"ik min Data Rate for IK:\", ik_df[\"DataRate\"].min())\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zErPGBRCb6dw"
      },
      "source": [
        "## number of devices vs. SNR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fxoi4Bopb5hV"
      },
      "outputs": [],
      "source": [
        "# 1. Compute the average noise per 5-minute interval\n",
        "# 2. Merge with the unique transmitter counts\n",
        "# 3. Scatter plot of # of devices vs. average noise\n",
        "\n",
        "# For am\n",
        "am_5min_interval = am_df['Sniff_Timestamp'].dt.floor('5min')\n",
        "device_counts_am = am_filtered.groupby('5_min_interval')['Trans_Addr'].nunique().reset_index(name='Unique_Devices')\n",
        "avg_SNR_am = am_filtered.groupby(\"5_min_interval\")[\"SNR\"].mean().reset_index(name=\"Avg_SNR\")\n",
        "merged_SNR_df = pd.merge(device_counts_am, avg_SNR_am, on=\"5_min_interval\", how=\"inner\")\n",
        "fig = px.scatter(merged_SNR_df, x=\"Unique_Devices\", y=\"Avg_SNR\", labels=labels,trendline=\"ols\")\n",
        "save_or_show(fig, \"snr_vs_devices_am\")\n",
        "#calculate R squared\n",
        "x = merged_SNR_df[\"Unique_Devices\"]\n",
        "y = merged_SNR_df[\"Avg_SNR\"]\n",
        "x = sm.add_constant(x)  # Adds a constant term to the predictor\n",
        "model = sm.OLS(y, x)\n",
        "results = model.fit()\n",
        "print(results.rsquared)\n",
        "\n",
        "# For cc\n",
        "avg_SNR_cc = cc_filtered.groupby(\"5_min_interval\")[\"SNR\"].mean().reset_index(name=\"Avg_SNR\")\n",
        "merged_SNR_df = pd.merge(device_counts_cc, avg_SNR_cc, on=\"5_min_interval\", how=\"inner\")\n",
        "fig = px.scatter(merged_SNR_df, x=\"Unique_Devices\", y=\"Avg_SNR\", labels=labels, trendline=\"ols\")\n",
        "save_or_show(fig, \"snr_vs_devices_cc\")\n",
        "#calculate R squared\n",
        "x = merged_SNR_df[\"Unique_Devices\"]\n",
        "y = merged_SNR_df[\"Avg_SNR\"]\n",
        "model = sm.OLS(y, x)\n",
        "results = model.fit()\n",
        "print(results.rsquared)\n",
        "\n",
        "# For ik\n",
        "avg_SNR_ik = ik_filtered.groupby(\"5_min_interval\")[\"SNR\"].mean().reset_index(name=\"Avg_SNR\")\n",
        "merged_SNR_df = pd.merge(device_counts_ik, avg_SNR_ik, on=\"5_min_interval\", how=\"inner\")\n",
        "fig = px.scatter(merged_SNR_df, x=\"Unique_Devices\", y=\"Avg_SNR\", labels=labels, trendline=\"ols\")\n",
        "save_or_show(fig, \"snr_vs_devices_ik\")\n",
        "#calculate R squared\n",
        "x = merged_SNR_df[\"Unique_Devices\"]\n",
        "y = merged_SNR_df[\"Avg_SNR\"]\n",
        "model = sm.OLS(y, x)\n",
        "results = model.fit()\n",
        "print(results.rsquared)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JhT0wiM70-fm"
      },
      "source": [
        "## Number of Devices VS Retransmission Rates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dSk84UTQ1C0k"
      },
      "outputs": [],
      "source": [
        "# Calculate total retries per 5-minute interval\n",
        "# Calculate total packets per 5-minute interval\n",
        "# Calculate Retry Rate (retries / total packets)\n",
        "# Merge the calculated metrics with the unique transmitter counts\n",
        "# Scatter plot of # of devices vs. Retry Rate with trendline\n",
        "\n",
        "# For am\n",
        "total_retries_am = am_filtered.groupby(\"5_min_interval\")[\"FC_Retry\"].sum().reset_index(name=\"Avg_Retries\")\n",
        "total_packets_am = am_filtered.groupby(\"5_min_interval\")[\"FC_Retry\"].count().reset_index(name=\"Total_Packets\")\n",
        "total_retries_am[\"Retry_Rate\"] = total_retries_am[\"Avg_Retries\"] / total_packets_am[\"Total_Packets\"]\n",
        "merged_SNR_df = pd.merge(device_counts_am, total_retries_am[[\"5_min_interval\", \"Retry_Rate\"]], on=\"5_min_interval\", how=\"inner\")\n",
        "fig = px.scatter(merged_SNR_df, x=\"Unique_Devices\", y=\"Retry_Rate\", labels=labels, trendline=\"ols\")\n",
        "save_or_show(fig, \"devices_vs_retry_rate_am\")\n",
        "#calculate R squared#calculate R squared\n",
        "x = merged_SNR_df[\"Unique_Devices\"]\n",
        "y = merged_SNR_df[\"Retry_Rate\"]\n",
        "model = sm.OLS(y, x)\n",
        "results = model.fit()\n",
        "print(results.rsquared)\n",
        "\n",
        "# For cc\n",
        "total_retries_cc = cc_filtered.groupby(\"5_min_interval\")[\"FC_Retry\"].sum().reset_index(name=\"Avg_Retries\")\n",
        "total_packets_cc = cc_filtered.groupby(\"5_min_interval\")[\"FC_Retry\"].count().reset_index(name=\"Total_Packets\")\n",
        "total_retries_cc[\"Retry_Rate\"] = total_retries_cc[\"Avg_Retries\"] / total_packets_cc[\"Total_Packets\"]\n",
        "merged_SNR_df = pd.merge(device_counts_cc, total_retries_cc[[\"5_min_interval\", \"Retry_Rate\"]], on=\"5_min_interval\", how=\"inner\")\n",
        "fig = px.scatter(merged_SNR_df, x=\"Unique_Devices\", y=\"Retry_Rate\", labels=labels, trendline=\"ols\")\n",
        "save_or_show(fig, \"devices_vs_retry_rate_cc\")\n",
        "#calculate R squared#calculate R squared\n",
        "x = merged_SNR_df[\"Unique_Devices\"]\n",
        "y = merged_SNR_df[\"Retry_Rate\"]\n",
        "model = sm.OLS(y, x)\n",
        "results = model.fit()\n",
        "print(results.rsquared)\n",
        "\n",
        "# For ik\n",
        "total_retries_ik = ik_filtered.groupby(\"5_min_interval\")[\"FC_Retry\"].sum().reset_index(name=\"Avg_Retries\")\n",
        "total_packets_ik = ik_filtered.groupby(\"5_min_interval\")[\"FC_Retry\"].count().reset_index(name=\"Total_Packets\")\n",
        "total_retries_ik[\"Retry_Rate\"] = total_retries_ik[\"Avg_Retries\"] / total_packets_ik[\"Total_Packets\"]\n",
        "merged_SNR_df = pd.merge(device_counts_ik, total_retries_ik[[\"5_min_interval\", \"Retry_Rate\"]], on=\"5_min_interval\", how=\"inner\")\n",
        "fig = px.scatter(merged_SNR_df, x=\"Unique_Devices\", y=\"Retry_Rate\", labels=labels, trendline=\"ols\")\n",
        "save_or_show(fig, \"devices_vs_retry_rate_ik\")\n",
        "#calculate R squared#calculate R squared\n",
        "x = merged_SNR_df[\"Unique_Devices\"]\n",
        "y = merged_SNR_df[\"Retry_Rate\"]\n",
        "model = sm.OLS(y, x)\n",
        "results = model.fit()\n",
        "print(results.rsquared)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-kTAEac_6UqG"
      },
      "source": [
        "## Number of Devices vs Number of Transmissions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4IVwtKq16X4E"
      },
      "outputs": [],
      "source": [
        "# Calculate total packets per 5-minute interval\n",
        "# Merge the calculated metrics with the unique transmitter counts\n",
        "# Scatter plot of # of devices vs. Retry Rate with trendline\n",
        "\n",
        "# For am\n",
        "#add 5min interval to am_df so we can use it to dedine the amount of retries\n",
        "\n",
        "\n",
        "total_packets_am = am_df.groupby(\"5_min_interval\")[\"FC_Retry\"].count().reset_index(name=\"Total_Packets\")\n",
        "merged_SNR_df = pd.merge(device_counts_am, total_packets_am[[\"5_min_interval\", \"Total_Packets\"]], on=\"5_min_interval\", how=\"inner\")\n",
        "fig = px.scatter(merged_SNR_df, x=\"Unique_Devices\", y=\"Total_Packets\", labels=labels, trendline=\"ols\")\n",
        "save_or_show(fig, \"devices_vs_total_packets_am\")\n",
        "#calculate R squared#calculate R squared\n",
        "x = merged_SNR_df[\"Unique_Devices\"]\n",
        "y = merged_SNR_df[\"Total_Packets\"]\n",
        "model = sm.OLS(y, x)\n",
        "results = model.fit()\n",
        "print(results.rsquared)\n",
        "\n",
        "\n",
        "# For cc\n",
        "total_packets_cc = cc_filtered.groupby(\"5_min_interval\")[\"FC_Retry\"].count().reset_index(name=\"Total_Packets\")\n",
        "merged_SNR_df = pd.merge(device_counts_cc, total_packets_cc[[\"5_min_interval\", \"Total_Packets\"]], on=\"5_min_interval\", how=\"inner\")\n",
        "fig = px.scatter(merged_SNR_df, x=\"Unique_Devices\", y=\"Total_Packets\", labels=labels, trendline=\"ols\")\n",
        "save_or_show(fig, \"devices_vs_total_packets_cc\")\n",
        "#calculate R squared#calculate R squared\n",
        "x = merged_SNR_df[\"Unique_Devices\"]\n",
        "y = merged_SNR_df[\"Total_Packets\"]\n",
        "model = sm.OLS(y, x)\n",
        "results = model.fit()\n",
        "print(results.rsquared)\n",
        "\n",
        "\n",
        "# For ik\n",
        "total_packets_ik = ik_filtered.groupby(\"5_min_interval\")[\"FC_Retry\"].count().reset_index(name=\"Total_Packets\")\n",
        "merged_SNR_df = pd.merge(device_counts_ik, total_packets_ik[[\"5_min_interval\", \"Total_Packets\"]], on=\"5_min_interval\", how=\"inner\")\n",
        "fig = px.scatter(merged_SNR_df, x=\"Unique_Devices\", y=\"Total_Packets\", labels=labels, trendline=\"ols\")\n",
        "save_or_show(fig, \"devices_vs_total_packets_ik\")\n",
        "#calculate R squared#calculate R squared\n",
        "x = merged_SNR_df[\"Unique_Devices\"]\n",
        "y = merged_SNR_df[\"Total_Packets\"]\n",
        "model = sm.OLS(y, x)\n",
        "results = model.fit()\n",
        "print(results.rsquared)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3CqTWm5I3pP"
      },
      "source": [
        "## Frame Types"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Bg6bPjpI03w"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "\n",
        "# Prepare list to hold the data for each dataframe and each frame category\n",
        "data = []\n",
        "for df, label in zip([am_df, cc_df, ik_df], ['am', 'cc', 'ik']):\n",
        "    total_frames = len(df)\n",
        "\n",
        "    # Type 0 (Management) frames:\n",
        "    beacon_count = len(df[(df[\"FC_Type\"] == 0) & (df[\"FC_Subtype\"] == 8)]) # Beacon frames: Subtype 8\n",
        "    probe_count = len(df[(df[\"FC_Type\"] == 0) & (df[\"FC_Subtype\"] == 5)])  # Probe response frames: Subtype 5\n",
        "    other_type0_count = len(df[(df[\"FC_Type\"] == 0) & (~df[\"FC_Subtype\"].isin([8, 5]))]) # Other management frames\n",
        "\n",
        "    # Type 1 (Control) frames:\n",
        "    type1_count = len(df[df[\"FC_Type\"] == 1])\n",
        "\n",
        "    # Type 2 (Data) frames: isolate additional subtypes\n",
        "    data_count = len(df[(df[\"FC_Type\"] == 2) & (df[\"FC_Subtype\"] == 0)]) # Data frames: Subtype 0\n",
        "    null_count = len(df[(df[\"FC_Type\"] == 2) & (df[\"FC_Subtype\"] == 4)]) # Null (no data) frames: Subtype 4\n",
        "    qos_data_count = len(df[(df[\"FC_Type\"] == 2) & (df[\"FC_Subtype\"] == 8)]) # QoS Data frames: Subtype 8\n",
        "    qos_null_count = len(df[(df[\"FC_Type\"] == 2) & (df[\"FC_Subtype\"] == 12)]) # QoS Null (no data) frames: Subtype 12\n",
        "    other_type2_count = len(df[(df[\"FC_Type\"] == 2) & (~df[\"FC_Subtype\"].isin([0, 4, 8, 12]))]) # Any other type 2 frames\n",
        "\n",
        "    # Calculate percentages for each category (guard against division by zero)\n",
        "    beacon_pct = (beacon_count / total_frames) * 100 if total_frames > 0 else 0\n",
        "    probe_pct = (probe_count / total_frames) * 100 if total_frames > 0 else 0\n",
        "    #assoc_pct = (assoc_count / total_frames) * 100 if total_frames > 0 else 0\n",
        "    other0_pct = (other_type0_count / total_frames) * 100 if total_frames > 0 else 0\n",
        "    type1_pct = (type1_count / total_frames) * 100 if total_frames > 0 else 0\n",
        "    data_pct = (data_count / total_frames) * 100 if total_frames > 0 else 0\n",
        "    null_pct = (null_count / total_frames) * 100 if total_frames > 0 else 0\n",
        "    qos_data_pct = (qos_data_count / total_frames) * 100 if total_frames > 0 else 0\n",
        "    qos_null_pct = (qos_null_count / total_frames) * 100 if total_frames > 0 else 0\n",
        "    other2_pct = (other_type2_count / total_frames) * 100 if total_frames > 0 else 0\n",
        "\n",
        "    # Append data for Type 0 categories\n",
        "    data.append({\"DataFrame\": label, \"Frame Category\": \"Beacon (0,8)\", \"Percentage\": beacon_pct})\n",
        "    data.append({\"DataFrame\": label, \"Frame Category\": \"Probe Response (0,5)\", \"Percentage\": probe_pct})\n",
        "\n",
        "    if other_type0_count > 0:\n",
        "        data.append({\"DataFrame\": label, \"Frame Category\": \"Other Mgmt Frames (0,*)\", \"Percentage\": other0_pct})\n",
        "\n",
        "    # Append data for Type 1 (Control) frames\n",
        "    data.append({\"DataFrame\": label, \"Frame Category\": \"Control Frames (1,*)\", \"Percentage\": type1_pct})\n",
        "\n",
        "    # Append data for Type 2 subcategories\n",
        "    if data_count > 0:\n",
        "        data.append({\"DataFrame\": label, \"Frame Category\": \"Data Frames (2,0)\", \"Percentage\": data_pct})\n",
        "    if null_count > 0:\n",
        "        data.append({\"DataFrame\": label, \"Frame Category\": \"Null (no data) (2,4)\", \"Percentage\": null_pct})\n",
        "    if qos_data_count > 0:\n",
        "        data.append({\"DataFrame\": label, \"Frame Category\": \"QoS Data (2,8)\", \"Percentage\": qos_data_pct})\n",
        "    if qos_null_count > 0:\n",
        "        data.append({\"DataFrame\": label, \"Frame Category\": \"QoS Null (no data) (2,12)\", \"Percentage\": qos_null_pct})\n",
        "    if other_type2_count > 0:\n",
        "        data.append({\"DataFrame\": label, \"Frame Category\": \"Other Data Frames (2,*)\", \"Percentage\": other2_pct})\n",
        "\n",
        "# Create a dataframe from the list\n",
        "plot_df = pd.DataFrame(data)\n",
        "\n",
        "# Create a stacked bar chart using Plotly Express\n",
        "fig = px.bar(\n",
        "    plot_df,\n",
        "    x=\"DataFrame\",\n",
        "    y=\"Percentage\",\n",
        "    color=\"Frame Category\",\n",
        "    barmode=\"stack\",\n",
        "    labels={\"Percentage\": \"Percentage (%)\", \"DataFrame\": \"DataFrame\"},\n",
        "    color_discrete_map={\n",
        "                \"Beacon (0,8)\": \"#0C5DA5\",\n",
        "                \"Probe Response (0,5)\": \"#DD2C00\",\n",
        "                \"Null (no data) (2,4)\": \"#FF9500\",\n",
        "                \"QoS Null (no data) (2,12)\": \"#9e9e9e\",\n",
        "                \"Data Frames (2,0)\": \"#845B97\",\n",
        "                \"Other Mgmt Frames (0,*)\": \"#474747\",\n",
        "                \"QoS Data (2,8)\": \"#00B945\",\n",
        "                \"Other Data Frames (2,*)\": \"yellow\"}\n",
        ")\n",
        "fig.update_layout(\n",
        "    legend_title=\"Frame (type,subtype)\"\n",
        ")\n",
        "# ['0C5DA5', '00B945', 'FF9500', 'FF2C00', '845B97', '474747', '9e9e9e']\n",
        "# Save or show the figure using the provided function\n",
        "save_or_show(fig, \"frame_types\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3gQxpCipuGYQ"
      },
      "source": [
        "## Resolved hostnames"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V3uJJmZEuG3j"
      },
      "outputs": [],
      "source": [
        "def plot_resolved_hostnames(df, title):\n",
        "    df_filtered = df[[\"Src_Name\", \"Dst_Name\", \"DataRate\"]].copy()\n",
        "    df_filtered = df_filtered.melt(id_vars=[\"DataRate\"], value_name=\"Host\").dropna(subset=[\"Host\"])\n",
        "\n",
        "    # Calculate hostname counts and average data rate\n",
        "    hostname_counts = df_filtered.groupby(\"Host\").size().reset_index(name=\"Count\")\n",
        "    avg_data_rate = df_filtered.groupby(\"Host\")[\"DataRate\"].mean().reset_index(name=\"Avg_DataRate\")\n",
        "    hostname_counts = hostname_counts.merge(avg_data_rate, on=\"Host\")\n",
        "\n",
        "    # Calculate total and percentage for each host\n",
        "    total = hostname_counts[\"Count\"].sum()\n",
        "    hostname_counts[\"Percent\"] = hostname_counts[\"Count\"] / total * 100\n",
        "\n",
        "    # Combine fields with less than 1% into \"Other\" category\n",
        "    other_hosts = hostname_counts[hostname_counts[\"Percent\"] < 1]\n",
        "    other = other_hosts.sum(numeric_only=True)\n",
        "    other[\"Host\"] = \"Other\"\n",
        "    other[\"Avg_DataRate\"] = (other_hosts[\"Count\"] * other_hosts[\"Avg_DataRate\"]).sum() / other[\"Count\"]\n",
        "    hostname_counts = hostname_counts[hostname_counts[\"Percent\"] >= 1]\n",
        "    hostname_counts = pd.concat([hostname_counts, pd.DataFrame([other])], ignore_index=True)\n",
        "\n",
        "    # Create pie chart using the custom label\n",
        "    hostname_counts[\"Label\"] = hostname_counts.apply(\n",
        "        lambda row: f'{row[\"Host\"]} ({row[\"Avg_DataRate\"]:.2f} Mbps)', axis=1\n",
        "    )\n",
        "    fig = px.pie(\n",
        "        hostname_counts,\n",
        "        names=\"Label\",\n",
        "        values=\"Count\",\n",
        "        hole=0.3,\n",
        "    )\n",
        "\n",
        "    fig.update_traces(textposition=\"inside\", textinfo=\"percent+label\")\n",
        "    fig.update_layout(showlegend=False)\n",
        "    save_or_show(fig, title)\n",
        "\n",
        "plot_resolved_hostnames(cc_df, \"resolved_hostnames_cc\")\n",
        "plot_resolved_hostnames(ik_df, \"resolved_hostnames_ik\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J03N70f72dKu"
      },
      "source": [
        "## Site usage by devices over time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c12SEK5G1TV2"
      },
      "outputs": [],
      "source": [
        "def plot_site_usage(df, bssids, site, title):\n",
        "  # Create a bar chart of devices per time interval colored by the number of devices using \"site\"\n",
        "  df_filtered = df.loc[~df['Trans_Addr'].isin(bssids)].copy()\n",
        "  df_filtered[\"Interval\"] = df_filtered[\"Sniff_Timestamp\"].dt.floor(\"5min\")\n",
        "  device_counts = (df_filtered.groupby(\"Interval\")[\"Trans_Addr\"].nunique()\n",
        "                   .reset_index(name=\"Unique_Devices\"))\n",
        "  site_counts = (df_filtered[\n",
        "      df_filtered[\"Src_Name\"].str.contains(site, case=False, na=False) |\n",
        "      df_filtered[\"Dst_Name\"].str.contains(site, case=False, na=False)\n",
        "      ].groupby(\"Interval\")[\"Trans_Addr\"].nunique().reset_index(name=\"Num Devices\"))\n",
        "  merged_counts = pd.merge(device_counts, site_counts, on=\"Interval\", how=\"left\")\n",
        "  merged_counts[\"Num Devices\"].fillna(0, inplace=True)\n",
        "  fig = px.bar(merged_counts, x=\"Interval\", y=\"Unique_Devices\", color=\"Num Devices\",\n",
        "               color_continuous_scale=\"Viridis\", labels=labels).update_layout(showlegend=True)\n",
        "  save_or_show(fig, title)\n",
        "\n",
        "# site = \"chatgpt.com\"\n",
        "# site = \"facebook.com\"\n",
        "# site = \"google.com\"\n",
        "# site = \"fbcdn.net\"\n",
        "# site = \"overleaf.com\"\n",
        "# site = \"github.com\"\n",
        "site = \"1e100.net\"\n",
        "\n",
        "plot_site_usage(cc_df, bssids_cc, site, \"site_usage_cc\")\n",
        "plot_site_usage(ik_df, bssids_ik, site, \"site_usage_ik\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NXcwPesjSbo8"
      },
      "source": [
        "# Download Generated Figures"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NcEjOTG2RPXB"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "\n",
        "if DOWNLOAD_FIGURES:\n",
        "  !zip -r figures.zip figures/\n",
        "  files.download(\"figures.zip\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "2UyQ0lkGTJzx",
        "A2TN_WzwUQ2J",
        "TnWTmLZ-AuVc",
        "9tcp8KB-DYBo",
        "a3X9UUhVgS81",
        "G4h6_A1qgX_e",
        "zErPGBRCb6dw",
        "JhT0wiM70-fm",
        "-kTAEac_6UqG",
        "NXcwPesjSbo8"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}